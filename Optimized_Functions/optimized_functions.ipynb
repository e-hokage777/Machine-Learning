{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fd586a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from itertools import combinations_with_replacement as combs_r\n",
    "from itertools import combinations as combs\n",
    "\n",
    "####                    OPTIMIZTED GRADIENT DESCENT FUNCTION                   ####\n",
    "def gradientDescent(X,y,theta, num_iters, alpha):\n",
    "    m = X.shape[0]\n",
    "    costs = np.zeros((num_iters,1));\n",
    "    thetas = np.zeros((num_iters,theta.size));\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        temp_thetas = (theta - alpha * ((np.dot(X.transpose(),(np.dot(X,theta)-y)))/m))\n",
    "\n",
    "        theta = temp_thetas\n",
    "        thetas[i] = temp_thetas.reshape(1,temp_thetas.size)\n",
    "        costs[i] = calculateCost(X,y,theta)\n",
    "        \n",
    "        # plotting costs against the number of iterations\n",
    "        # to check if gradient descent is working properly\n",
    "        fig = plt.figure(figsize=(12,6))\n",
    "        plt.title(\"Costs against number of iterations\")\n",
    "        plt.ylabel(\"Costs\")\n",
    "        plt.xlabel(\"Number of iterations\")\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "    return {\"hypothesis_theta\":theta, \"costs\": costs, \"thetas\":thetas}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    OPTIMIZTED FEATURE NORMALIZATION FUNCTION                   ####\n",
    "def featureNormalize(features):\n",
    "    #Getting necessary variables\n",
    "    means = features.mean(axis = 0)\n",
    "    stds = features.std(axis = 0)\n",
    "\n",
    "    featuresNorm = (features-means)/stds\n",
    "            \n",
    "    \n",
    "    return {\"normalized_features\":featuresNorm, \"means\":means, \"stds\":stds}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    OPTIMIZTED FEATURE ADDITION FUNCTION                  ####\n",
    "\n",
    "def addFeatures(X, num_combinations):\n",
    "    if(num_combinations == 1 or num_combinations == 0):\n",
    "        return X\n",
    "    \n",
    "    new_X = X\n",
    "    num_features = X.shape[1]\n",
    "    num_training_examples = X.shape[0]\n",
    "    new_features = []\n",
    "    #finding the number of permutations of the features\n",
    "   \n",
    "    \n",
    "    for c in range(2, num_combinations+1):\n",
    "        feature_combinations = combs_r(range(num_features),c)\n",
    "        for feature_combination in feature_combinations:\n",
    "            accumulator = 1\n",
    "            for i in feature_combination:\n",
    "                accumulator *= new_X[:, i]\n",
    "\n",
    "            new_X = np.concatenate([new_X, accumulator.reshape(num_training_examples,1)], axis=1)\n",
    "        \n",
    "    return new_X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    NORMAL EQUATION FUNCTION                  ####\n",
    "def normalEquation(X,y):\n",
    "    X_t = X.transpose();\n",
    "    hypothesis_theta = np.dot(np.linalg.pinv(np.dot(X_t,X)),np.dot(X_t,y))\n",
    "    return hypothesis_theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    REGULARIZED NORMAL EQUATION FUNCTION                  ####\n",
    "def normalEquationReg(X,y,l):\n",
    "    X_t = X.transpose();\n",
    "    X_Xt = np.dot(X_t,X)\n",
    "    identity = np.eye(X_Xt.shape[0],X_Xt.shape[1])\n",
    "    identity[0,0] = 0\n",
    "    hypothesis_theta = np.dot(np.linalg.pinv(X_Xt + l*(identity)),np.dot(X_t,y))\n",
    "    return hypothesis_theta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    OPTIMIZED FUNCTION FOR CROSS VALIDATION                  ####\n",
    "def crossValidate(X,y, X_cv, y_cv, num_degrees, title, ylabel):\n",
    "    #setting up variable to hold final costs and degrees arrays\n",
    "    costs = np.zeros(num_degrees)\n",
    "    costs_cv = np.zeros(num_degrees)\n",
    "    degrees = np.zeros(num_degrees)\n",
    "    \n",
    "    ##Testing for each of degrees in range num_degrees\n",
    "    for i in range(1, num_degrees+1):\n",
    "        temp_X = addFeatures(temp_X, i)\n",
    "        temp_X = np.insert(temp_X, 0, 1, axis=1)\n",
    "        temp_X_cv = addFeatures(temp_X_cv, i)\n",
    "        temp_X_cv = np.insert(temp_X_cv, 0, 1, axis=1)\n",
    "        \n",
    "        theta = normalEquation(temp_X, y)\n",
    "        costs[i-1] = calculateCost(temp_X, y, theta)\n",
    "        costs_cv[i-1] = calculateCost(temp_X_cv, y_cv, theta)\n",
    "        degrees[i-1] = i\n",
    "        \n",
    "    ##plotting the costs against degrees for both CV data and Training data\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Degrees\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(degrees,costs, label=\"Training data\")\n",
    "    plt.plot(degrees,costs_cv, label=\"Cv data\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    ##Obtaining and returning the degree that produced the minimum cost CV data\n",
    "    min_cost = min(costs_cv)\n",
    "    min_degree = np.array(np.where(costs_cv == min_cost))[0][0] + 1\n",
    "    \n",
    "    return min_degree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                    OPTIMIZED FUNCTION FOR FINDING OPTIMAL LAMBDA                  ####\n",
    "## Function for finding optiaml lambda\n",
    "def optimalLambda(X, y, X_cv, y_cv, lambdas, degree, title, ylabel):\n",
    "    size_lambdas = lambdas.size\n",
    "    costs = np.zeros(size_lambdas)\n",
    "    costs_cv = np.zeros(size_lambdas)\n",
    "    temp_X = addFeatures(X,degree)\n",
    "    temp_X_cv = addFeatures(X_cv,degree)\n",
    "    temp_X = np.insert(temp_X,0,1,axis=1)\n",
    "    temp_X_cv = np.insert(temp_X_cv,0,1,axis=1)\n",
    "    \n",
    "    for i in range(size_lambdas):\n",
    "        theta = normalEquationReg(temp_X,y,lambdas[i])\n",
    "        costs[i] = calculateCost(temp_X,y,theta)\n",
    "        costs_cv[i] = calculateCost(temp_X_cv,y_cv,theta)\n",
    "        \n",
    "    ##plotting the costs against lambdas for both CV data and Training data\n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Lambdas\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(lambdas,costs, label=\"Training data\")\n",
    "    plt.plot(lambdas,costs_cv, label=\"Cv data\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    ##Obtaining and returning the degree that produced the minimum cost CV data\n",
    "    min_cost = min(costs_cv)\n",
    "    min_lambda = lambdas[np.array(np.where(costs_cv == min_cost))[0][0]]\n",
    "    return min_lambda\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "####                    FUNCTION FOR SEPARATING DATA INTO TRAINING, CROSS VALIDATION AND TEST                  ####\n",
    "### -----NB: the data also returns the training data size\n",
    "\n",
    "def trs_cvs_ts(X):\n",
    "    \n",
    "    ## !!! HAVE TO IMPORT math MODULE BEFORE RUNNING THIS FUNCTION\n",
    "    \n",
    "    num_training_egs = X.shape[0]\n",
    "    training_data_size = 0.6 * num_training_egs\n",
    "    cvs_ts_size = 0.2 * num_training_egs\n",
    "    \n",
    "    tr = 0\n",
    "    cv = 0\n",
    "    \n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "#     #checking if flooring all would equal the number of training egs\n",
    "#     if (int(training_data_size) + 2 * math.ceil(cvs_ts_size)) == num_training_egs:\n",
    "#         tr = int(training_data_size)\n",
    "#         cv = tr + math.ceil(cvs_ts_size)\n",
    "#         ts = tr + cv + math.ceil(cvs_ts_size)\n",
    "#     elif (math.ceil(training_data) + 2 * int(cvs_ts_size)) == num_training_egs:\n",
    "#         tr = math.ceil(training_data_size)\n",
    "#         cv = tr + int(cvs_ts_size)\n",
    "#         ts = tr + cv + int(cvs_ts_size)\n",
    "#     else:\n",
    "#         tr = int(training_data_size)\n",
    "#         cv = tr + int(cvs_ts_size)\n",
    "#         ts = tr + cv + int(cvs_ts_size)\n",
    "        \n",
    "    data[\"trs\"] = X[0:tr, :]\n",
    "    data[\"cvs\"] = X[tr:tr+cv, :]\n",
    "    data[\"ts\"] = X[tr+cv:0, :]\n",
    "    data[\"trs_size\"] = tr\n",
    "    data[\"cvs_size\"]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####                   OPTIMIZED FUNCTION FOR CHECKING BEST SIZE AND COMBINATIONS OF AVAILABLE FEATURES                 ####\n",
    "def bestParams(X,y):\n",
    "    features_size = X.shape[1]\n",
    "    features  = range(features_size)\n",
    "    diff_combs = []\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(1,features_size+1):\n",
    "        c = cc(features,i)\n",
    "        for combo in c:\n",
    "            diff_combs.append(list(combo))\n",
    "    \n",
    "    for combo in diff_combs:\n",
    "        test_features = X[:,combo]\n",
    "        test_features = np.insert(test_features,0,1,axis=1)\n",
    "    \n",
    "        trcvts = trs_cvs_ts(test_features)\n",
    "        X_tr = trcvts[\"trs\"]\n",
    "        X_cv = trcvts[\"cvs\"]\n",
    "        X_t = trcvts[\"ts\"]\n",
    "        trs_size = trcvts[\"trs_size\"]\n",
    "        cvs_size = trcvts[\"cvs_size\"]\n",
    "        last_index = trcvts[\"last_index\"]\n",
    "        \n",
    "        y_tr = y[0:trs_size, :]\n",
    "        y_cv = y[trs_size:cvs_size, :]\n",
    "        y_t = y[cvs_size:last_index,:]\n",
    "        \n",
    "        theta = normalEquation(X_tr, y_tr)\n",
    "        \n",
    "        costs.append(calculateCost(X_cv, y_cv, theta))\n",
    "\n",
    "        \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    plt.title(\"Test different sizes and combinations of features\")\n",
    "    plt.xlabel(\"Index of combinattion\")\n",
    "    plt.ylabel(\"Costs\")\n",
    "    plt.plot(costs, \"rx\")\n",
    "    plt.show()\n",
    "    \n",
    "    result = {}\n",
    "    min_cost = min(costs)\n",
    "    min_combo = diff_combs[costs.index(min(costs))]\n",
    "    \n",
    "    result[\"min_cost\"] = min_cost\n",
    "    result[\"min_combo\"] = min_combo\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
